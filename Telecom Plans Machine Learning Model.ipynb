{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending a phone plan for Megaline users\n",
    "This project is focused on developing a model that would analyze subscibers' behavior, thereby, recommending one of Megaline's latest phone plans: Smart or Ultra. We want a model that is at least 75% accurate. This is a classification task, therefore, we will test the Decision Tree, Random Forest, and Logistic Regression classifiers\n",
    "\n",
    "### Data Description\n",
    "\n",
    "\n",
    "- `calls:` numbers of calls \n",
    "- `minutes:` total call duration in minutes\n",
    "- `messages:` number of text messages\n",
    "- `mb_used:` internet traffic used in MB\n",
    "- `is_ultra:` plan for the current month (Ultra - 1, Smart - 0)\n",
    "\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. General Information\n",
    "2. Splitting into training, validation, and test sets\n",
    "3. Testing Models\n",
    "4. Quality Check on the Test Set\n",
    "5. Sanity Check: Model vs Chance \n",
    "6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import set_config\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users = pd.read_csv(\"/datasets/users_behavior.csv\")\n",
    "\n",
    "data_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the dataset, we see that there are no missing values in the all columns. However, we will convert the columns  \"calls\" and \"messages\" to intergers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the values in \"calls\" column from float to integer\n",
    "data_users[\"calls\"] = data_users[\"calls\"].astype(\"int\")\n",
    "\n",
    "#Converting the values in \"calls\" column from float to integer\n",
    "data_users[\"messages\"] = data_users[\"messages\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   int64  \n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   int64  \n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we need three datasets, one for training, the other for validation, and the third for testing the accuracy of our model. The percentages of the original dataset would be set at 60 for training, 20 for validation, and 20 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data_users into data_users_train (60%) and data_users_valid (40%)\n",
    "\n",
    "data_users_train, data = train_test_split(data_users, test_size = 0.4, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 5)\n",
      "(1286, 5)\n"
     ]
    }
   ],
   "source": [
    "#Getting the shape of the training and testing datasets\n",
    "\n",
    "print(data_users_train.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 5)\n",
      "(643, 5)\n"
     ]
    }
   ],
   "source": [
    "#splitting data into data_users_valid (50%) and data_users_test (50%)\n",
    "\n",
    "data_users_valid, data_users_test = train_test_split(data, test_size = 0.5, random_state = 12345)\n",
    "\n",
    "#Getting the shape of the validation and testing datasets\n",
    "print(data_users_valid.shape)\n",
    "print(data_users_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the features and target sections for each set. For the features, we will call all the columns in the  dataframe but drop the target column. The target is the **is_ultra** column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the training features\n",
    "train_features = data_users_train.drop('is_ultra', axis=1)\n",
    "\n",
    "#defining the training target feature\n",
    "train_target = data_users_train['is_ultra']\n",
    "\n",
    "#defining the validation features\n",
    "valid_features = data_users_valid.drop('is_ultra', axis=1)\n",
    "\n",
    "#defining the validation target feature\n",
    "valid_target = data_users_valid['is_ultra']\n",
    "\n",
    "#defining the test features\n",
    "test_features = data_users_test.drop('is_ultra', axis=1)\n",
    "\n",
    "#defining the target feature\n",
    "test_target = data_users_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features for each dataset has been defined. Now, we want to train, validate, and test the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the best model for out dataset, we will test the dataset with Decision Tree, Random Forest, and Logistic Regression models. First, we train them with the training dataset, and then test them on the validation set by comparing a prediction using features from the validation set to the actual target from the validation set. For each phase, we will tweak hyperparameters so we can get a higher accuracy score, the latter being the metric for choosing the best model to move forward with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Decision Tree model, we be calling the DecisionTreeClassifier() function. The hyperparameters that we would be making use of are random_state and max_depth. The random state will be given a fixed value of 12345, while the max_depth parameter will be varied from 1 to 12, and then we would print the model with the best accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy is: 0.7853810264385692 with a depth of: 3\n"
     ]
    }
   ],
   "source": [
    "best_model  = None\n",
    "\n",
    "best_result = 0\n",
    "\n",
    "best_depth = 0\n",
    "\n",
    "for x in range (1, 13):\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = x)\n",
    "    \n",
    "    model.fit(train_features, train_target)\n",
    "    \n",
    "    predictions_valid = model.predict(valid_features)\n",
    "    \n",
    "    result = accuracy_score(valid_target, predictions_valid)\n",
    "    \n",
    "    if result > best_result:\n",
    "        \n",
    "        best_result = result\n",
    "        \n",
    "        best_depth = x\n",
    "    \n",
    "print(\"The best accuracy is:\", best_result, \"with a depth of:\", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree model has the best accuracy of 78.53% when the max_depth is 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Random Forest model, we be calling the RandomForestClassifier() function. The hyperparameters that we would be making use of are random_state and the n_estimators. Then we will loop through values of max_depth, and within that loop, loop through values of n_estimators. We will use this loop to create models with different permutations of max_depth and n_estimators values that we will store in the list, from which we will choose the model with the highest accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the best model on the validation set: 0.8087091757387247 n_estimators: 40 best_depth: 8\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = None\n",
    "\n",
    "best_result_rf = 0\n",
    "\n",
    "best_est_rf = 0\n",
    "\n",
    "best_depth_rf = 0\n",
    "\n",
    "for est in range (10, 71, 10): #loops through values of est from 1 to 70 with a step of 10 for n_estimators\n",
    "    for depth in range(1, 13): #loops through various depths of trees from 1 to 12\n",
    "        model_rf = RandomForestClassifier(random_state = 12345, max_depth = depth, n_estimators = est)\n",
    "        model_rf.fit(train_features, train_target)\n",
    "        \n",
    "        predictions_valid_rf = model_rf.predict(valid_features)\n",
    "        \n",
    "        result = accuracy_score(valid_target, predictions_valid_rf)\n",
    "        \n",
    "        if result > best_result_rf:\n",
    "            \n",
    "            best_rf_model = model\n",
    "            \n",
    "            best_est_rf = est\n",
    "            \n",
    "            best_depth_rf = depth\n",
    "            \n",
    "            best_result_rf = result\n",
    "            \n",
    "print(\"The accuracy of the best model on the validation set:\", best_result_rf, \"n_estimators:\", best_est_rf,\n",
    "                                         \"best_depth:\", best_depth_rf)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result tells us that the best random forest classifier model is the one with max_depth of 8 and n_estimators=40, with an accuracy score is 80.87%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the LogisticRegression() function. The random_state parameter stays the same, and the solver is set to  'liblinear'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy = 0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "model_lr.fit(train_features, train_target)\n",
    "\n",
    "valid_pred_lr = model_lr.predict(valid_features)\n",
    "\n",
    "print(\"Logistic Regression Accuracy =\", accuracy_score(valid_target, valid_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of our Logistic Regression model is 75.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model we have come up with is the Random Forest model with an accuracy score of 80.9%, max_depth=8 and n_estimators=40. Coming in second place is Decision Tree model with max_depth=3 (accuracy score 78.53%). The last is Logistic Regression with an accuracy score of 75.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Check on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model that we got will be used on our test set. However, we need to retrain the model using both the training and validation sets combined. To combine those sets, we can use the pd.concat function which takes a list of the sets invoved as argument, and set the parameter axis=0 to make it a vertical stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2571 entries, 3027 to 3197\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     2571 non-null   int64  \n",
      " 1   minutes   2571 non-null   float64\n",
      " 2   messages  2571 non-null   int64  \n",
      " 3   mb_used   2571 non-null   float64\n",
      " 4   is_ultra  2571 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 120.5 KB\n"
     ]
    }
   ],
   "source": [
    "merged_tables = pd.concat([data_users_train, data_users_valid], axis = 0)#vertically stacks the training and validation sets\n",
    "merged_tables.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>60</td>\n",
       "      <td>431.56</td>\n",
       "      <td>26</td>\n",
       "      <td>14751.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>33</td>\n",
       "      <td>265.17</td>\n",
       "      <td>59</td>\n",
       "      <td>17398.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>52</td>\n",
       "      <td>341.83</td>\n",
       "      <td>68</td>\n",
       "      <td>15462.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>42</td>\n",
       "      <td>226.18</td>\n",
       "      <td>21</td>\n",
       "      <td>13243.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>30</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0</td>\n",
       "      <td>8189.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "3027     60   431.56        26  14751.26         0\n",
       "434      33   265.17        59  17398.02         0\n",
       "1226     52   341.83        68  15462.38         0\n",
       "1054     42   226.18        21  13243.48         0\n",
       "1842     30   198.42         0   8189.53         0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_tables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the features and the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features = merged_tables.drop('is_ultra', axis=1)\n",
    "merged_target = merged_tables['is_ultra']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our model using the new features and target, and make predictions using the features from the test set, and get an accuracy score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7993779160186625\n"
     ]
    }
   ],
   "source": [
    "model_best_rf = RandomForestClassifier(random_state=12345, max_depth=8, n_estimators=40)\n",
    "\n",
    "model_best_rf.fit(merged_features, merged_target)\n",
    "\n",
    "predicted_rf = model_best_rf.predict(test_features)\n",
    "\n",
    "print(accuracy_score(predicted_rf, test_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an accuracy score of 79.93%, which is over the 75% threshold for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the sanity of our model, we compare it with the target feature \"is_ultra\" in our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_check_data = data_users_test[\"is_ultra\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.684292\n",
      "1    0.315708\n",
      "Name: is_ultra, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(san_check_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of **Smart** clients is 68.4%, and the percentage of **Ultra** clients is 31.6%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we analyze the class frequencies of the Random Forest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.785381\n",
      "1    0.214619\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=12345, max_depth=8, n_estimators=40)\n",
    "\n",
    "model_rf.fit(merged_features, merged_target)\n",
    "\n",
    "predicted_valid = pd.Series(model_rf.predict(test_features))\n",
    "\n",
    "rf_class_frequency = predicted_valid.value_counts(normalize = True)\n",
    "\n",
    "print(rf_class_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a baseline model, which is a constant model that predicts 0 for any observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "#Creating a baseline model\n",
    "\n",
    "target_pred_constant = pd.Series(0, index = data_users_test.index)\n",
    "\n",
    "print(accuracy_score(test_target, target_pred_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model has a prediction of 68.4% which is lower than 79.93%(~80%) of our random forest classifier. So the random forest classifier passes the sanity check. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was done to develop a model that would analyze subscibers' behavior, thereby, recommending one of Megaline's latest phone plans: Smart or Ultra. The data was split into training, validation and test datasets. After testing the models, Random Forest Classifier performed best with an accuracy score of approximately 81% on the validation dataset, and approximately 80% on the test dataset.\n",
    "\n",
    "Also,the baseline model has an accuracy score of 68.4% which is lower than 79.93%(~80%) of our random forest classifier. So the random forest classifier passes the sanity check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
